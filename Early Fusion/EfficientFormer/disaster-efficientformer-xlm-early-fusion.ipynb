{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-14T03:28:16.772880Z",
     "iopub.status.busy": "2024-07-14T03:28:16.772185Z",
     "iopub.status.idle": "2024-07-14T03:28:17.205964Z",
     "shell.execute_reply": "2024-07-14T03:28:17.205058Z",
     "shell.execute_reply.started": "2024-07-14T03:28:16.772844Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Paths to the CSV files and image directories\n",
    "csv_paths = {\n",
    "    'Train': 'G:\\\\new dataset\\\\Disaster_train.csv',\n",
    "    'Test': 'G:\\\\new dataset\\\\Disaster_test.csv',\n",
    "    'Validation': 'G:\\\\new dataset\\\\Disaster_val.csv'\n",
    "}\n",
    "\n",
    "image_dirs = {\n",
    "    'Train': 'G:\\\\new dataset\\\\Train',\n",
    "    'Test': 'G:\\\\new dataset\\\\Test',\n",
    "    'Validation': 'G:\\\\new dataset\\\\Validation'\n",
    "}\n",
    "\n",
    "output_dir = 'G:\\\\new dataset\\\\Output'  # Output directory to save the CSV files\n",
    "\n",
    "# Function to check for matching Meme_ID and image files, and add image paths\n",
    "def check_matches(csv_path, image_dir):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    image_files = os.listdir(image_dir)\n",
    "    image_names = {os.path.splitext(image_file)[0]: os.path.join(image_dir, image_file) for image_file in image_files}\n",
    "    \n",
    "    # Add Image_Path column to the dataframe\n",
    "    df['Image_Path'] = df['image_id'].apply(lambda x: image_names.get(x, None))\n",
    "    \n",
    "    # Filter rows where Image_Path is not None (i.e., matched Meme_IDs)\n",
    "    matched_df = df[df['Image_Path'].notna()]\n",
    "    \n",
    "    return matched_df\n",
    "\n",
    "# Check matches for each set (Train, Test, Validation)\n",
    "for key in csv_paths:\n",
    "    matched_df = check_matches(csv_paths[key], image_dirs[key])\n",
    "    \n",
    "    matches_output_path = os.path.join(output_dir, f'{key}_matches.csv')\n",
    "    \n",
    "    matched_df.to_csv(matches_output_path, index=False)\n",
    "    \n",
    "    print(f\"{key} set:\")\n",
    "    print(f\"Matched Meme_IDs with image paths saved to {matches_output_path}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T03:28:20.358038Z",
     "iopub.status.busy": "2024-07-14T03:28:20.357691Z",
     "iopub.status.idle": "2024-07-14T03:28:20.380435Z",
     "shell.execute_reply": "2024-07-14T03:28:20.379431Z",
     "shell.execute_reply.started": "2024-07-14T03:28:20.358009Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('G:\\\\new dataset\\\\Output\\\\Train_matches.csv')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T03:28:22.142467Z",
     "iopub.status.busy": "2024-07-14T03:28:22.141703Z",
     "iopub.status.idle": "2024-07-14T03:28:22.156351Z",
     "shell.execute_reply": "2024-07-14T03:28:22.155425Z",
     "shell.execute_reply.started": "2024-07-14T03:28:22.142427Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('G:\\\\new dataset\\\\Output\\\\Test_matches.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T03:28:24.419798Z",
     "iopub.status.busy": "2024-07-14T03:28:24.419465Z",
     "iopub.status.idle": "2024-07-14T03:28:24.433978Z",
     "shell.execute_reply": "2024-07-14T03:28:24.432893Z",
     "shell.execute_reply.started": "2024-07-14T03:28:24.419771Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_df = pd.read_csv('G:\\\\new dataset\\\\Output\\\\Validation_matches.csv')\n",
    "validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T03:28:26.395975Z",
     "iopub.status.busy": "2024-07-14T03:28:26.395361Z",
     "iopub.status.idle": "2024-07-14T03:28:26.400937Z",
     "shell.execute_reply": "2024-07-14T03:28:26.399930Z",
     "shell.execute_reply.started": "2024-07-14T03:28:26.395941Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display the sizes of each split\n",
    "print(f\"Train dataset size: {len(train_df)}\")\n",
    "print(f\"Test dataset size: {len(test_df)}\")\n",
    "print(f\"Validation dataset size: {len(validation_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T03:28:28.948872Z",
     "iopub.status.busy": "2024-07-14T03:28:28.948521Z",
     "iopub.status.idle": "2024-07-14T03:28:28.991963Z",
     "shell.execute_reply": "2024-07-14T03:28:28.991116Z",
     "shell.execute_reply.started": "2024-07-14T03:28:28.948842Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Function to remove punctuation (preserve Bangla characters)\n",
    "def remove_punctuation(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# Function to remove extra whitespace\n",
    "def remove_whitespace(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "# Function to remove emojis\n",
    "def remove_emojis(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "# Function to remove URLs\n",
    "def remove_urls(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "# Function to remove HTML tags\n",
    "def remove_html(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    html_pattern = re.compile(r'<.*?>')\n",
    "    return html_pattern.sub(r'', text)\n",
    "\n",
    "# Function to remove special characters (preserve Bangla characters)\n",
    "def remove_special_characters(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    return re.sub(r'[^A-Za-z0-9\\s\\u0980-\\u09FF]', '', text)\n",
    "\n",
    "# Combine all cleaning functions\n",
    "def clean_text(text):\n",
    "    text = remove_urls(text)\n",
    "    text = remove_html(text)\n",
    "    text = remove_emojis(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_special_characters(text)\n",
    "    text = remove_whitespace(text)\n",
    "    return text\n",
    "\n",
    "# Mapping categories to integers\n",
    "category_mapping = {\n",
    "    'Landslides': 0,\n",
    "    'Wildfire': 1,\n",
    "    'Drought': 2,\n",
    "    'Flood': 3,\n",
    "    'Earthquake': 4,\n",
    "    'Tropical Storm': 5,\n",
    "    'Non Disaster': 6,\n",
    "    'Human Damage': 7,\n",
    "}\n",
    "\n",
    "# Load and clean the dataframes\n",
    "csv_paths = {\n",
    "    'Train': 'G:\\\\new dataset\\\\Output\\\\Train_matches.csv',\n",
    "    'Test': 'G:\\\\new dataset\\\\Output\\\\Test_matches.csv',\n",
    "    'Validation': 'G:\\\\new dataset\\\\Output\\\\Validation_matches.csv'\n",
    "}\n",
    "\n",
    "cleaned_output_paths = {\n",
    "    'Train': 'G:\\\\new dataset\\\\Output\\\\Train_matches_cleaned.csv',\n",
    "    'Test': 'G:\\\\new dataset\\\\Output\\\\Test_matches_cleaned.csv',\n",
    "    'Validation': 'G:\\\\new dataset\\\\Output\\\\Validation_matches_cleaned.csv'\n",
    "}\n",
    "\n",
    "text_columns = ['context', 'category']\n",
    "\n",
    "for key in csv_paths:\n",
    "    # Load the dataframe\n",
    "    df = pd.read_csv(csv_paths[key])\n",
    "    \n",
    "    # Apply cleaning to all relevant text columns\n",
    "    for column in text_columns:\n",
    "        df[column] = df[column].astype(str).apply(clean_text)\n",
    "    \n",
    "    # Map 'category' column to integers\n",
    "    df['category'] = df['category'].map(category_mapping)\n",
    "    \n",
    "    # Add 'label' column (same as 'category' for now)\n",
    "    df['label'] = df['category']\n",
    "    \n",
    "    # Display the cleaned dataframe\n",
    "    print(f\"Cleaned {key} dataframe:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Save the cleaned dataframe to a new CSV file\n",
    "    df.to_csv(cleaned_output_paths[key], index=False)\n",
    "    print(f\"Cleaned dataframe saved to {cleaned_output_paths[key]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T03:28:33.303345Z",
     "iopub.status.busy": "2024-07-14T03:28:33.302709Z",
     "iopub.status.idle": "2024-07-14T03:28:33.321597Z",
     "shell.execute_reply": "2024-07-14T03:28:33.320582Z",
     "shell.execute_reply.started": "2024-07-14T03:28:33.303313Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('G:\\\\new dataset\\\\Output\\\\Train_matches_cleaned.csv')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T03:28:35.039973Z",
     "iopub.status.busy": "2024-07-14T03:28:35.039625Z",
     "iopub.status.idle": "2024-07-14T03:28:35.053722Z",
     "shell.execute_reply": "2024-07-14T03:28:35.052739Z",
     "shell.execute_reply.started": "2024-07-14T03:28:35.039943Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('G:\\\\new dataset\\\\Output\\\\Test_matches_cleaned.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T03:28:37.328920Z",
     "iopub.status.busy": "2024-07-14T03:28:37.328236Z",
     "iopub.status.idle": "2024-07-14T03:28:37.342770Z",
     "shell.execute_reply": "2024-07-14T03:28:37.341826Z",
     "shell.execute_reply.started": "2024-07-14T03:28:37.328886Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_df = pd.read_csv('G:\\\\new dataset\\\\Output\\\\Validation_matches_cleaned.csv')\n",
    "validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T03:28:39.643195Z",
     "iopub.status.busy": "2024-07-14T03:28:39.642278Z",
     "iopub.status.idle": "2024-07-14T03:28:45.331398Z",
     "shell.execute_reply": "2024-07-14T03:28:45.330595Z",
     "shell.execute_reply.started": "2024-07-14T03:28:39.643162Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from transformers import BertTokenizer, BertModel, AdamW\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T03:28:45.333215Z",
     "iopub.status.busy": "2024-07-14T03:28:45.332796Z",
     "iopub.status.idle": "2024-07-14T03:29:09.326732Z",
     "shell.execute_reply": "2024-07-14T03:29:09.325586Z",
     "shell.execute_reply.started": "2024-07-14T03:28:45.333188Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T04:01:54.223509Z",
     "iopub.status.busy": "2024-07-14T04:01:54.222626Z",
     "iopub.status.idle": "2024-07-14T04:01:54.737314Z",
     "shell.execute_reply": "2024-07-14T04:01:54.736353Z",
     "shell.execute_reply.started": "2024-07-14T04:01:54.223475Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, EfficientFormerModel\n",
    "import torch\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"snap-research/efficientformer-l1-300\")\n",
    "model = EfficientFormerModel.from_pretrained(\"snap-research/efficientformer-l1-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T04:01:56.467543Z",
     "iopub.status.busy": "2024-07-14T04:01:56.467153Z",
     "iopub.status.idle": "2024-07-14T04:01:57.316570Z",
     "shell.execute_reply": "2024-07-14T04:01:57.315592Z",
     "shell.execute_reply.started": "2024-07-14T04:01:56.467509Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, XLMRobertaModel, AdamW\n",
    "# Initialize BERT tokenizer and model\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "bert_model = XLMRobertaModel.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T04:01:59.152150Z",
     "iopub.status.busy": "2024-07-14T04:01:59.151260Z",
     "iopub.status.idle": "2024-07-14T04:01:59.156986Z",
     "shell.execute_reply": "2024-07-14T04:01:59.156125Z",
     "shell.execute_reply.started": "2024-07-14T04:01:59.152117Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T04:02:02.962567Z",
     "iopub.status.busy": "2024-07-14T04:02:02.961993Z",
     "iopub.status.idle": "2024-07-14T04:02:02.966539Z",
     "shell.execute_reply": "2024-07-14T04:02:02.965698Z",
     "shell.execute_reply.started": "2024-07-14T04:02:02.962535Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Enable device-side assertions\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T04:02:04.295669Z",
     "iopub.status.busy": "2024-07-14T04:02:04.294611Z",
     "iopub.status.idle": "2024-07-14T04:02:04.333232Z",
     "shell.execute_reply": "2024-07-14T04:02:04.332172Z",
     "shell.execute_reply.started": "2024-07-14T04:02:04.295628Z"
    }
   },
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T04:02:08.262615Z",
     "iopub.status.busy": "2024-07-14T04:02:08.262147Z",
     "iopub.status.idle": "2024-07-14T04:02:08.459198Z",
     "shell.execute_reply": "2024-07-14T04:02:08.458277Z",
     "shell.execute_reply.started": "2024-07-14T04:02:08.262582Z"
    }
   },
   "outputs": [],
   "source": [
    "bert_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T04:02:12.251490Z",
     "iopub.status.busy": "2024-07-14T04:02:12.251115Z",
     "iopub.status.idle": "2024-07-14T04:02:12.262604Z",
     "shell.execute_reply": "2024-07-14T04:02:12.261652Z",
     "shell.execute_reply.started": "2024-07-14T04:02:12.251457Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "max_seq_length = 512  # Set your desired maximum sequence length for BERT\n",
    "\n",
    "# Define the pre-processing transformations for images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "class MyMultimodalDataset(Dataset):\n",
    "    def __init__(self, data, transform=None, tokenizer=None, max_seq_length=512):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.data.iloc[idx]['Image_Path']\n",
    "        #print(image_path)\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            if self.transform is not None:\n",
    "                image = self.transform(image)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image at index {idx}: {e}\")\n",
    "            return None, None, None, None\n",
    "\n",
    "        if image is None:\n",
    "            print(f\"Error loading image at idx for None {idx}: {image_path}\")\n",
    "            \n",
    "            return None, None, None, None\n",
    "\n",
    "        context = self.data.iloc[idx]['context']\n",
    "\n",
    "        inputs = self.tokenizer(context, padding='max_length', truncation=True, max_length=self.max_seq_length, return_tensors='pt')\n",
    "        input_ids = inputs['input_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "\n",
    "        label = self.data.iloc[idx]['label']\n",
    "\n",
    "        return image, input_ids, attention_mask, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T04:02:15.006696Z",
     "iopub.status.busy": "2024-07-14T04:02:15.006284Z",
     "iopub.status.idle": "2024-07-14T04:02:15.021701Z",
     "shell.execute_reply": "2024-07-14T04:02:15.020603Z",
     "shell.execute_reply.started": "2024-07-14T04:02:15.006666Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create custom datasets with MyMultimodalDataset\n",
    "train_dataset = MyMultimodalDataset(train_df, transform=transform, tokenizer=bert_tokenizer, max_seq_length=max_seq_length)\n",
    "test_dataset = MyMultimodalDataset(test_df, transform=transform, tokenizer=bert_tokenizer, max_seq_length=max_seq_length)\n",
    "val_dataset = MyMultimodalDataset(validation_df, transform=transform, tokenizer=bert_tokenizer, max_seq_length=max_seq_length)\n",
    "\n",
    "# Define data loaders\n",
    "batch_size = 6  # Set your desired batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T04:15:57.701358Z",
     "iopub.status.busy": "2024-07-14T04:15:57.700637Z",
     "iopub.status.idle": "2024-07-14T04:15:59.731852Z",
     "shell.execute_reply": "2024-07-14T04:15:59.730958Z",
     "shell.execute_reply.started": "2024-07-14T04:15:57.701328Z"
    }
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torchvision.models as models\n",
    "# from transformers import AutoImageProcessor, ViTModel, AutoTokenizer, DistilBertModel, AdamW\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Assuming you have defined your train_loader, val_loader, optimizer, criterion, model, bert_model, etc.\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Feature dimensions from ViTModel and DistilBertModel\n",
    "img_feat_size = 448  # Updated based on the debug print output\n",
    "text_feat_size = 768\n",
    "combined_input_dim = img_feat_size + text_feat_size\n",
    "\n",
    "# Define the regressor model outside the training loop\n",
    "regressor = torch.nn.Sequential(\n",
    "    torch.nn.Linear(combined_input_dim, 512),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(512, 8)  # Change output size to match your number of labels\n",
    ").to(device)\n",
    "\n",
    "# Combine parameters from both models and the regressor for the optimizer\n",
    "optimizer = torch.optim.AdamW(list(model.parameters()) + list(bert_model.parameters()) + list(regressor.parameters()), lr=0.0001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 35\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    running_train_loss = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    bert_model.train()\n",
    "    regressor.train()\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
    "    for images, texts, attention_masks, labels in tqdm(train_loader, desc='Training', leave=False):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device).long()\n",
    "\n",
    "        input_ids = texts.squeeze(1).to(device)\n",
    "        attention_mask = attention_masks.squeeze(1).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs_image = model(pixel_values=images)\n",
    "        img_hidden_states = outputs_image.last_hidden_state\n",
    "        img_feats = img_hidden_states[:, 0, :]\n",
    "\n",
    "        outputs_text = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_hidden_states = outputs_text.last_hidden_state\n",
    "        text_feats = text_hidden_states[:, 0, :]\n",
    "\n",
    "        combined_feats = torch.cat((img_feats, text_feats), dim=1)\n",
    "\n",
    "        predictions = regressor(combined_feats).float()\n",
    "        loss = criterion(predictions, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += loss.item()\n",
    "\n",
    "    epoch_train_loss = running_train_loss / len(train_loader)\n",
    "    train_losses.append(epoch_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    bert_model.eval()\n",
    "    regressor.eval()\n",
    "\n",
    "    running_val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_images, val_texts, val_attention_masks, val_labels in tqdm(val_loader, desc='val', leave=False):\n",
    "            val_images = val_images.to(device)\n",
    "            val_labels = val_labels.to(device).long()\n",
    "\n",
    "            val_input_ids = val_texts.squeeze(1).to(device)\n",
    "            val_attention_mask = val_attention_masks.squeeze(1).to(device)\n",
    "\n",
    "            outputs_image = model(pixel_values=val_images)\n",
    "            val_img_hidden_states = outputs_image.last_hidden_state\n",
    "            val_img_feats = val_img_hidden_states[:, 0, :]\n",
    "\n",
    "            outputs_text = bert_model(input_ids=val_input_ids, attention_mask=val_attention_mask)\n",
    "            val_text_hidden_states = outputs_text.last_hidden_state\n",
    "            val_text_feats = val_text_hidden_states[:, 0, :]\n",
    "\n",
    "            val_combined_feats = torch.cat((val_img_feats, val_text_feats), dim=1)\n",
    "\n",
    "            val_predictions = regressor(val_combined_feats).float()\n",
    "            val_loss = criterion(val_predictions, val_labels)\n",
    "            # Debugging prints\n",
    "#             print(\"Shapes:\")\n",
    "#             print(f\"val_images: {val_images.shape}\")\n",
    "#             print(f\"val_labels: {val_labels.shape}\")\n",
    "#             print(f\"val_input_ids: {val_input_ids.shape}\")\n",
    "#             print(f\"val_attention_mask: {val_attention_mask.shape}\")\n",
    "#             print(f\"val_img_feats: {val_img_feats.shape}\")\n",
    "#             print(f\"val_text_feats: {val_text_feats.shape}\")\n",
    "#             print(f\"val_combined_feats: {val_combined_feats.shape}\")\n",
    "#             print(f\"val_predictions: {val_predictions.shape}\")\n",
    "#             print(f\"val_loss: {val_loss.item()}\")\n",
    "\n",
    "            running_val_loss += val_loss.item()\n",
    "\n",
    "    epoch_val_loss = running_val_loss / len(val_loader)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}] - \"\n",
    "          f\"Train Loss: {epoch_train_loss:.4f}, \"\n",
    "          f\"Val Loss: {epoch_val_loss:.4f}\")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Total execution time: {execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare lists to store predicted and true labels\n",
    "predicted_labels = []\n",
    "true_labels = []\n",
    "\n",
    "model.eval()\n",
    "bert_model.eval()\n",
    "regressor.eval()\n",
    "\n",
    "running_test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_images, test_texts, test_attention_masks, test_labels in tqdm(test_loader, desc='Testing', leave=False):\n",
    "        test_images = test_images.to(device)\n",
    "        test_labels = test_labels.to(device).long()\n",
    "\n",
    "        test_input_ids = test_texts.squeeze(1).to(device)\n",
    "        test_attention_mask = test_attention_masks.squeeze(1).to(device)\n",
    "\n",
    "        outputs_image = model(pixel_values=test_images)\n",
    "        test_img_hidden_states = outputs_image.last_hidden_state\n",
    "        test_img_feats = test_img_hidden_states[:, 0, :]\n",
    "\n",
    "        outputs_text = bert_model(input_ids=test_input_ids, attention_mask=test_attention_mask)\n",
    "        test_text_hidden_states = outputs_text.last_hidden_state\n",
    "        test_text_feats = test_text_hidden_states[:, 0, :]\n",
    "\n",
    "        test_combined_feats = torch.cat((test_img_feats, test_text_feats), dim=1)\n",
    "\n",
    "        test_predictions = regressor(test_combined_feats).float()\n",
    "        test_loss = criterion(test_predictions, test_labels)\n",
    "\n",
    "        running_test_loss += test_loss.item()\n",
    "\n",
    "        # Store predicted and true labels\n",
    "        predicted_labels.extend(test_predictions.argmax(dim=1).cpu().numpy())\n",
    "        true_labels.extend(test_labels.cpu().numpy())\n",
    "\n",
    "epoch_test_loss = running_test_loss / len(test_loader)\n",
    "print(f\"Test Loss: {epoch_test_loss:.4f}\")\n",
    "\n",
    "# Convert lists to numpy arrays for further evaluation\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "true_labels = np.array(true_labels)\n",
    "\n",
    "# You can now use predicted_labels and true_labels for further evaluation\n",
    "# For example, calculating accuracy, precision, recall, etc.\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T04:19:15.793033Z",
     "iopub.status.busy": "2024-07-14T04:19:15.792622Z",
     "iopub.status.idle": "2024-07-14T04:19:15.800963Z",
     "shell.execute_reply": "2024-07-14T04:19:15.800001Z",
     "shell.execute_reply.started": "2024-07-14T04:19:15.792999Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T04:19:17.890088Z",
     "iopub.status.busy": "2024-07-14T04:19:17.889463Z",
     "iopub.status.idle": "2024-07-14T04:19:17.895540Z",
     "shell.execute_reply": "2024-07-14T04:19:17.894699Z",
     "shell.execute_reply.started": "2024-07-14T04:19:17.890058Z"
    }
   },
   "outputs": [],
   "source": [
    "true_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T04:19:20.123252Z",
     "iopub.status.busy": "2024-07-14T04:19:20.122565Z",
     "iopub.status.idle": "2024-07-14T04:19:20.137871Z",
     "shell.execute_reply": "2024-07-14T04:19:20.136918Z",
     "shell.execute_reply.started": "2024-07-14T04:19:20.123222Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, mean_squared_error, classification_report\n",
    "\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate precision, recall, F1-score overall (macro average)\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='macro')\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate Sensitivity (Recall) for each class\n",
    "sensitivity_per_class = recall\n",
    "\n",
    "# Calculate Specificity for each class\n",
    "specificity_per_class = []\n",
    "for i in range(len(conf_matrix)):\n",
    "    tn = np.sum(conf_matrix) - (np.sum(conf_matrix[i, :]) + np.sum(conf_matrix[:, i]) - conf_matrix[i, i])\n",
    "    fp = np.sum(conf_matrix[:, i]) - conf_matrix[i, i]\n",
    "    specificity_per_class.append(tn / (tn + fp))\n",
    "\n",
    "# Print overall calculated metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision (macro): {precision}\")\n",
    "print(f\"Recall (macro): {recall}\")\n",
    "print(f\"F1-Score (macro): {f1_score}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Print Sensitivity and Specificity for each class\n",
    "print(f\"Sensitivity (Recall) for each class: {sensitivity_per_class}\")\n",
    "print(f\"Specificity for each class: {specificity_per_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping categories to integers\n",
    "class_names = [\n",
    "    'Landslides',\n",
    "    'Wildfire',\n",
    "    'Drought',\n",
    "    'Flood',\n",
    "    'Earthquake',\n",
    "    'Tropical Storm',\n",
    "    'Non Disaster',\n",
    "    'Human Damage']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "# Class names according to the label encoding mapping\n",
    "\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d',xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5384900,
     "sourceId": 8948385,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
