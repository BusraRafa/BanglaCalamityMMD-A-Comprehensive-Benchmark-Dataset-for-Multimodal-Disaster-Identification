{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-14T05:00:37.413924Z",
     "iopub.status.busy": "2024-07-14T05:00:37.413069Z",
     "iopub.status.idle": "2024-07-14T05:00:38.090578Z",
     "shell.execute_reply": "2024-07-14T05:00:38.089535Z",
     "shell.execute_reply.started": "2024-07-14T05:00:37.413890Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Paths to the CSV files and image directories\n",
    "csv_paths = {\n",
    "    'Train': '/kaggle/input/disaster/train.csv',\n",
    "    'Test': '/kaggle/input/disaster/test.csv',\n",
    "    'Validation': '/kaggle/input/disaster/validation.csv'\n",
    "}\n",
    " \n",
    "image_dirs = {\n",
    "    'Train': '/kaggle/input/disaster/train',\n",
    "    'Test': '/kaggle/input/disaster/test',\n",
    "    'Validation': '/kaggle/input/disaster/validation'\n",
    "}\n",
    "\n",
    "output_dir = '/kaggle/working/'  # Output directory to save the CSV files\n",
    "\n",
    "# Function to check for matching Meme_ID and image files, and add image paths\n",
    "def check_matches(csv_path, image_dir):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    image_files = os.listdir(image_dir)\n",
    "    image_names = {os.path.splitext(image_file)[0]: os.path.join(image_dir, image_file) for image_file in image_files}\n",
    "    \n",
    "    # Add Image_Path column to the dataframe\n",
    "    df['Image_Path'] = df['image_id'].apply(lambda x: image_names.get(x, None))\n",
    "    \n",
    "    # Filter rows where Image_Path is not None (i.e., matched Meme_IDs)\n",
    "    matched_df = df[df['Image_Path'].notna()]\n",
    "    \n",
    "    return matched_df\n",
    "\n",
    "# Check matches for each set (Train, Test, Validation)\n",
    "for key in csv_paths:\n",
    "    matched_df = check_matches(csv_paths[key], image_dirs[key])\n",
    "    \n",
    "    matches_output_path = os.path.join(output_dir, f'{key}_matches.csv')\n",
    "    \n",
    "    matched_df.to_csv(matches_output_path, index=False)\n",
    "    \n",
    "    print(f\"{key} set:\")\n",
    "    print(f\"Matched Meme_IDs with image paths saved to {matches_output_path}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T05:00:40.440705Z",
     "iopub.status.busy": "2024-07-14T05:00:40.439859Z",
     "iopub.status.idle": "2024-07-14T05:00:40.459282Z",
     "shell.execute_reply": "2024-07-14T05:00:40.457978Z",
     "shell.execute_reply.started": "2024-07-14T05:00:40.440668Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/kaggle/working/Train_matches.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T05:00:50.917771Z",
     "iopub.status.busy": "2024-07-14T05:00:50.917428Z",
     "iopub.status.idle": "2024-07-14T05:00:50.930175Z",
     "shell.execute_reply": "2024-07-14T05:00:50.929287Z",
     "shell.execute_reply.started": "2024-07-14T05:00:50.917745Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/kaggle/working/Test_matches.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T05:00:58.023556Z",
     "iopub.status.busy": "2024-07-14T05:00:58.023206Z",
     "iopub.status.idle": "2024-07-14T05:00:58.038129Z",
     "shell.execute_reply": "2024-07-14T05:00:58.036971Z",
     "shell.execute_reply.started": "2024-07-14T05:00:58.023528Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_df = pd.read_csv('/kaggle/working/Validation_matches.csv')\n",
    "validation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T05:01:00.180836Z",
     "iopub.status.busy": "2024-07-14T05:01:00.180485Z",
     "iopub.status.idle": "2024-07-14T05:01:00.186029Z",
     "shell.execute_reply": "2024-07-14T05:01:00.185085Z",
     "shell.execute_reply.started": "2024-07-14T05:01:00.180798Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display the sizes of each split\n",
    "print(f\"Train dataset size: {len(train_df)}\")\n",
    "print(f\"Test dataset size: {len(test_df)}\")\n",
    "print(f\"Validation dataset size: {len(validation_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T05:01:02.094218Z",
     "iopub.status.busy": "2024-07-14T05:01:02.093903Z",
     "iopub.status.idle": "2024-07-14T05:01:02.139751Z",
     "shell.execute_reply": "2024-07-14T05:01:02.138741Z",
     "shell.execute_reply.started": "2024-07-14T05:01:02.094194Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Function to remove punctuation (preserve Bangla characters)\n",
    "def remove_punctuation(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# Function to remove extra whitespace\n",
    "def remove_whitespace(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "# Function to remove emojis\n",
    "def remove_emojis(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "# Function to remove URLs\n",
    "def remove_urls(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "# Function to remove HTML tags\n",
    "def remove_html(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    html_pattern = re.compile(r'<.*?>')\n",
    "    return html_pattern.sub(r'', text)\n",
    "\n",
    "# Function to remove special characters (preserve Bangla characters)\n",
    "def remove_special_characters(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    return re.sub(r'[^A-Za-z0-9\\s\\u0980-\\u09FF]', '', text)\n",
    "\n",
    "# Combine all cleaning functions\n",
    "def clean_text(text):\n",
    "    text = remove_urls(text)\n",
    "    text = remove_html(text)\n",
    "    text = remove_emojis(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_special_characters(text)\n",
    "    text = remove_whitespace(text)\n",
    "    return text\n",
    "\n",
    "# Mapping categories to integers\n",
    "category_mapping = {\n",
    "    'Landslides': 0,\n",
    "    'Wildfire': 1,\n",
    "    'Drought': 2,\n",
    "    'Flood': 3,\n",
    "    'Earthquake': 4,\n",
    "    'Tropical Storm': 5,\n",
    "    'Non Disaster': 6,\n",
    "    'Human Damage': 7,\n",
    "}\n",
    "\n",
    "# Load and clean the dataframes\n",
    "csv_paths = {\n",
    "    'Train': '/kaggle/working/Train_matches.csv',\n",
    "    'Test': '/kaggle/working/Test_matches.csv',\n",
    "    'Validation': '/kaggle/working/Validation_matches.csv'\n",
    "}\n",
    "\n",
    "cleaned_output_paths = {\n",
    "    'Train': '/kaggle/working/Train_matches_cleaned.csv',\n",
    "    'Test': '/kaggle/working/Test_matches_cleaned.csv',\n",
    "    'Validation': '/kaggle/working/Validation_matches_cleaned.csv'\n",
    "}\n",
    "\n",
    "text_columns = ['context', 'category']\n",
    "\n",
    "for key in csv_paths:\n",
    "    # Load the dataframe\n",
    "    df = pd.read_csv(csv_paths[key])\n",
    "    \n",
    "    # Apply cleaning to all relevant text columns\n",
    "    for column in text_columns:\n",
    "        df[column] = df[column].astype(str).apply(clean_text)\n",
    "    \n",
    "    # Map 'category' column to integers\n",
    "    df['category'] = df['category'].map(category_mapping)\n",
    "    \n",
    "    # Add 'label' column (same as 'category' for now)\n",
    "    df['label'] = df['category']\n",
    "    \n",
    "    # Display the cleaned dataframe\n",
    "    print(f\"Cleaned {key} dataframe:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Save the cleaned dataframe to a new CSV file\n",
    "    df.to_csv(cleaned_output_paths[key], index=False)\n",
    "    print(f\"Cleaned dataframe saved to {cleaned_output_paths[key]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T05:01:07.840067Z",
     "iopub.status.busy": "2024-07-14T05:01:07.839706Z",
     "iopub.status.idle": "2024-07-14T05:01:07.856541Z",
     "shell.execute_reply": "2024-07-14T05:01:07.855587Z",
     "shell.execute_reply.started": "2024-07-14T05:01:07.840040Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/kaggle/working/Train_matches_cleaned.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T05:01:09.648491Z",
     "iopub.status.busy": "2024-07-14T05:01:09.647649Z",
     "iopub.status.idle": "2024-07-14T05:01:09.661538Z",
     "shell.execute_reply": "2024-07-14T05:01:09.660599Z",
     "shell.execute_reply.started": "2024-07-14T05:01:09.648459Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/kaggle/working/Test_matches_cleaned.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T05:01:11.403011Z",
     "iopub.status.busy": "2024-07-14T05:01:11.402177Z",
     "iopub.status.idle": "2024-07-14T05:01:11.417232Z",
     "shell.execute_reply": "2024-07-14T05:01:11.416403Z",
     "shell.execute_reply.started": "2024-07-14T05:01:11.402979Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_df = pd.read_csv('/kaggle/working/Validation_matches_cleaned.csv')\n",
    "validation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T05:01:13.269218Z",
     "iopub.status.busy": "2024-07-14T05:01:13.268836Z",
     "iopub.status.idle": "2024-07-14T05:01:18.893989Z",
     "shell.execute_reply": "2024-07-14T05:01:18.893026Z",
     "shell.execute_reply.started": "2024-07-14T05:01:13.269190Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from transformers import BertTokenizer, BertModel, AdamW\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T05:01:18.898319Z",
     "iopub.status.busy": "2024-07-14T05:01:18.897879Z",
     "iopub.status.idle": "2024-07-14T05:01:43.404935Z",
     "shell.execute_reply": "2024-07-14T05:01:43.403829Z",
     "shell.execute_reply.started": "2024-07-14T05:01:18.898285Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T05:14:00.830579Z",
     "iopub.status.busy": "2024-07-14T05:14:00.830003Z",
     "iopub.status.idle": "2024-07-14T05:14:02.873351Z",
     "shell.execute_reply": "2024-07-14T05:14:02.872543Z",
     "shell.execute_reply.started": "2024-07-14T05:14:00.830547Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, PvtModel\n",
    "import torch\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"Zetatech/pvt-tiny-224\")\n",
    "model = PvtModel.from_pretrained(\"Zetatech/pvt-tiny-224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T05:14:04.818537Z",
     "iopub.status.busy": "2024-07-14T05:14:04.817664Z",
     "iopub.status.idle": "2024-07-14T05:14:05.751599Z",
     "shell.execute_reply": "2024-07-14T05:14:05.750813Z",
     "shell.execute_reply.started": "2024-07-14T05:14:04.818503Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, XLMRobertaModel, AdamW\n",
    "# Initialize BERT tokenizer and model\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "bert_model = XLMRobertaModel.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T05:14:07.873283Z",
     "iopub.status.busy": "2024-07-14T05:14:07.872929Z",
     "iopub.status.idle": "2024-07-14T05:14:07.878395Z",
     "shell.execute_reply": "2024-07-14T05:14:07.877462Z",
     "shell.execute_reply.started": "2024-07-14T05:14:07.873256Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T05:14:10.026389Z",
     "iopub.status.busy": "2024-07-14T05:14:10.026030Z",
     "iopub.status.idle": "2024-07-14T05:14:10.030833Z",
     "shell.execute_reply": "2024-07-14T05:14:10.029875Z",
     "shell.execute_reply.started": "2024-07-14T05:14:10.026362Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Enable device-side assertions\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T05:14:12.115374Z",
     "iopub.status.busy": "2024-07-14T05:14:12.115017Z",
     "iopub.status.idle": "2024-07-14T05:14:12.147898Z",
     "shell.execute_reply": "2024-07-14T05:14:12.147038Z",
     "shell.execute_reply.started": "2024-07-14T05:14:12.115346Z"
    }
   },
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T05:14:15.954552Z",
     "iopub.status.busy": "2024-07-14T05:14:15.953674Z",
     "iopub.status.idle": "2024-07-14T05:14:16.157156Z",
     "shell.execute_reply": "2024-07-14T05:14:16.156152Z",
     "shell.execute_reply.started": "2024-07-14T05:14:15.954521Z"
    }
   },
   "outputs": [],
   "source": [
    "bert_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T05:14:19.233962Z",
     "iopub.status.busy": "2024-07-14T05:14:19.233578Z",
     "iopub.status.idle": "2024-07-14T05:14:19.245166Z",
     "shell.execute_reply": "2024-07-14T05:14:19.244269Z",
     "shell.execute_reply.started": "2024-07-14T05:14:19.233933Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "max_seq_length = 512  # Set your desired maximum sequence length for BERT\n",
    "\n",
    "# Define the pre-processing transformations for images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "class MyMultimodalDataset(Dataset):\n",
    "    def __init__(self, data, transform=None, tokenizer=None, max_seq_length=512):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.data.iloc[idx]['Image_Path']\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            if self.transform is not None:\n",
    "                image = self.transform(image)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image at index {idx}: {e}\")\n",
    "            return None, None, None, None\n",
    "\n",
    "        if image is None:\n",
    "            return None, None, None, None\n",
    "\n",
    "        context = self.data.iloc[idx]['context']\n",
    "\n",
    "        inputs = self.tokenizer(context, padding='max_length', truncation=True, max_length=self.max_seq_length, return_tensors='pt')\n",
    "        input_ids = inputs['input_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "\n",
    "        label = self.data.iloc[idx]['label']\n",
    "\n",
    "        return image, input_ids, attention_mask, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T05:14:22.188946Z",
     "iopub.status.busy": "2024-07-14T05:14:22.188295Z",
     "iopub.status.idle": "2024-07-14T05:14:22.203315Z",
     "shell.execute_reply": "2024-07-14T05:14:22.202302Z",
     "shell.execute_reply.started": "2024-07-14T05:14:22.188916Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create custom datasets with MyMultimodalDataset\n",
    "train_dataset = MyMultimodalDataset(train_df, transform=transform, tokenizer=bert_tokenizer, max_seq_length=max_seq_length)\n",
    "test_dataset = MyMultimodalDataset(test_df, transform=transform, tokenizer=bert_tokenizer, max_seq_length=max_seq_length)\n",
    "val_dataset = MyMultimodalDataset(validation_df, transform=transform, tokenizer=bert_tokenizer, max_seq_length=max_seq_length)\n",
    "\n",
    "# Define data loaders\n",
    "batch_size = 1  # Set your desired batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T05:20:29.270585Z",
     "iopub.status.busy": "2024-07-14T05:20:29.269884Z",
     "iopub.status.idle": "2024-07-14T05:20:31.419744Z",
     "shell.execute_reply": "2024-07-14T05:20:31.418661Z",
     "shell.execute_reply.started": "2024-07-14T05:20:29.270556Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from transformers import AutoImageProcessor, ViTModel, AutoTokenizer, DistilBertModel, AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Assuming you have defined your train_loader, val_loader, optimizer, criterion, model, bert_model, etc.\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Feature dimensions from ViTModel and DistilBertModel\n",
    "img_feat_size = 512\n",
    "text_feat_size = 768\n",
    "combined_input_dim = img_feat_size + text_feat_size\n",
    "\n",
    "# Define the early fusion model\n",
    "class EarlyFusionModel(torch.nn.Module):\n",
    "    def __init__(self, combined_input_dim, num_classes):\n",
    "        super(EarlyFusionModel, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(combined_input_dim, 512)\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.fc2 = torch.nn.Linear(512, num_classes)\n",
    "        \n",
    "    def forward(self, combined_feats):\n",
    "        x = torch.nn.functional.relu(self.fc1(combined_feats))\n",
    "        x = self.dropout(x)\n",
    "        output = self.fc2(x)\n",
    "        return output\n",
    "\n",
    "# Instantiate the fusion model\n",
    "num_classes = 8  # Adjust according to your number of labels\n",
    "fusion_model = EarlyFusionModel(combined_input_dim, num_classes).to(device)\n",
    "\n",
    "# Combine parameters from both models and the fusion model for the optimizer\n",
    "optimizer = torch.optim.AdamW(list(model.parameters()) + list(bert_model.parameters()) + list(fusion_model.parameters()), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 1\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Training time\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_train_loss = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    bert_model.train()\n",
    "    fusion_model.train()\n",
    "\n",
    "    for images, texts, attention_masks, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        input_ids = texts.squeeze(1).to(device)\n",
    "        attention_mask = attention_masks.squeeze(1).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass through image and text models\n",
    "        outputs_image = model(pixel_values=images)\n",
    "        img_hidden_states = outputs_image.last_hidden_state\n",
    "        img_feats = img_hidden_states[:, 0, :]\n",
    "\n",
    "        outputs_text = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_hidden_states = outputs_text.last_hidden_state\n",
    "        text_feats = text_hidden_states[:, 0, :]\n",
    "\n",
    "        # Combine the features early\n",
    "        combined_feats = torch.cat((img_feats, text_feats), dim=1)\n",
    "\n",
    "        # Forward pass through fusion model\n",
    "        predictions = fusion_model(combined_feats)\n",
    "        loss = criterion(predictions, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += loss.item()\n",
    "\n",
    "    epoch_train_loss = running_train_loss / len(train_loader)\n",
    "    train_losses.append(epoch_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    bert_model.eval()\n",
    "    fusion_model.eval()\n",
    "\n",
    "    running_val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_images, val_texts, val_attention_masks, val_labels in val_loader:\n",
    "            val_images = val_images.to(device)\n",
    "            val_labels = val_labels.to(device)\n",
    "\n",
    "            val_input_ids = val_texts.squeeze(1).to(device)\n",
    "            val_attention_mask = val_attention_masks.squeeze(1).to(device)\n",
    "\n",
    "            outputs_image = model(pixel_values=val_images)\n",
    "            val_img_hidden_states = outputs_image.last_hidden_state\n",
    "            val_img_feats = val_img_hidden_states[:, 0, :]\n",
    "\n",
    "            outputs_text = bert_model(input_ids=val_input_ids, attention_mask=val_attention_mask)\n",
    "            val_text_hidden_states = outputs_text.last_hidden_state\n",
    "            val_text_feats = val_text_hidden_states[:, 0, :]\n",
    "\n",
    "            val_combined_feats = torch.cat((val_img_feats, val_text_feats), dim=1)\n",
    "\n",
    "            val_predictions = fusion_model(val_combined_feats)\n",
    "            val_loss = criterion(val_predictions, val_labels)\n",
    "\n",
    "            running_val_loss += val_loss.item()\n",
    "\n",
    "    epoch_val_loss = running_val_loss / len(val_loader)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}] - \"\n",
    "          f\"Train Loss: {epoch_train_loss:.4f}, \"\n",
    "          f\"Val Loss: {epoch_val_loss:.4f}\")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Total execution time: {execution_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T05:23:31.770650Z",
     "iopub.status.busy": "2024-07-14T05:23:31.770271Z",
     "iopub.status.idle": "2024-07-14T05:23:32.106087Z",
     "shell.execute_reply": "2024-07-14T05:23:32.105197Z",
     "shell.execute_reply.started": "2024-07-14T05:23:31.770621Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Set your device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the combined classifier once\n",
    "combined_classifier = torch.nn.Sequential(\n",
    "    torch.nn.Linear(512 + 768, 512),  # Assuming img_feat_size = 512 and text_feat_size = 768\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(512, 8)  # Change the output size to match your number of labels\n",
    ").to(device)\n",
    "\n",
    "# Set models to evaluation mode\n",
    "model.eval()\n",
    "bert_model.eval()\n",
    "combined_classifier.eval()\n",
    "\n",
    "# Prepare lists to store predicted and true labels\n",
    "predicted_labels = []\n",
    "true_labels = []\n",
    "\n",
    "# Test loop\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_images, test_texts, test_attention_masks, test_labels in tqdm(test_loader, desc='Testing', leave=False):\n",
    "        test_images = test_images.to(device)\n",
    "        test_labels = test_labels.to(device)  \n",
    "        test_texts = test_texts.to(device)\n",
    "        test_attention_masks = test_attention_masks.to(device)\n",
    "\n",
    "        # Extract features from image-based model\n",
    "        outputs_image = model(pixel_values=test_images)\n",
    "        test_img_hidden_states = outputs_image.last_hidden_state\n",
    "        test_img_feats = test_img_hidden_states[:, 0, :]\n",
    "\n",
    "        # Extract features from text-based model (BERT)\n",
    "        test_texts = test_texts.squeeze(1)\n",
    "        test_attention_masks = test_attention_masks.squeeze(1)\n",
    "        test_outputs = bert_model(input_ids=test_texts, attention_mask=test_attention_masks)\n",
    "        \n",
    "        test_text_hidden_states = test_outputs.last_hidden_state\n",
    "        test_text_feats = test_text_hidden_states[:, 0, :]  \n",
    "\n",
    "        # Combine features early\n",
    "        combined_feats = torch.cat((test_img_feats, test_text_feats), dim=1)\n",
    "\n",
    "        # Classify combined features\n",
    "        combined_logits = combined_classifier(combined_feats)\n",
    "        test_predictions = torch.nn.functional.softmax(combined_logits, dim=1)\n",
    "        predicted_classes = torch.argmax(test_predictions, dim=1) + 1  # Revert back to labels from 1-5\n",
    "\n",
    "        predicted_labels.extend(predicted_classes.cpu().numpy())\n",
    "        true_labels.extend(test_labels.cpu().numpy().tolist())\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# Print or use the predicted labels and true labels as needed\n",
    "print(\"Predicted Labels:\", predicted_labels)\n",
    "print(\"True Labels:\", true_labels)\n",
    "print(f\"Total execution time for testing: {execution_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T05:23:36.330301Z",
     "iopub.status.busy": "2024-07-14T05:23:36.329517Z",
     "iopub.status.idle": "2024-07-14T05:23:36.335791Z",
     "shell.execute_reply": "2024-07-14T05:23:36.334963Z",
     "shell.execute_reply.started": "2024-07-14T05:23:36.330270Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T05:23:38.587150Z",
     "iopub.status.busy": "2024-07-14T05:23:38.586776Z",
     "iopub.status.idle": "2024-07-14T05:23:38.592998Z",
     "shell.execute_reply": "2024-07-14T05:23:38.592063Z",
     "shell.execute_reply.started": "2024-07-14T05:23:38.587122Z"
    }
   },
   "outputs": [],
   "source": [
    "true_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T05:23:40.314228Z",
     "iopub.status.busy": "2024-07-14T05:23:40.313871Z",
     "iopub.status.idle": "2024-07-14T05:23:40.329715Z",
     "shell.execute_reply": "2024-07-14T05:23:40.328836Z",
     "shell.execute_reply.started": "2024-07-14T05:23:40.314200Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, mean_squared_error, classification_report\n",
    "\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate precision, recall, F1-score overall (macro average)\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='macro')\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate Sensitivity (Recall) for each class\n",
    "sensitivity_per_class = recall\n",
    "\n",
    "# Calculate Specificity for each class\n",
    "specificity_per_class = []\n",
    "for i in range(len(conf_matrix)):\n",
    "    tn = np.sum(conf_matrix) - (np.sum(conf_matrix[i, :]) + np.sum(conf_matrix[:, i]) - conf_matrix[i, i])\n",
    "    fp = np.sum(conf_matrix[:, i]) - conf_matrix[i, i]\n",
    "    specificity_per_class.append(tn / (tn + fp))\n",
    "\n",
    "# Print overall calculated metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision (macro): {precision}\")\n",
    "print(f\"Recall (macro): {recall}\")\n",
    "print(f\"F1-Score (macro): {f1_score}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Print Sensitivity and Specificity for each class\n",
    "print(f\"Sensitivity (Recall) for each class: {sensitivity_per_class}\")\n",
    "print(f\"Specificity for each class: {specificity_per_class}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5384900,
     "sourceId": 8948385,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
